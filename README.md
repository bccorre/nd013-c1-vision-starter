# Object Detection in an Urban Environment

## Data

For this project, we will be using data from the [Waymo Open dataset](https://waymo.com/open/).

[OPTIONAL] - The files can be downloaded directly from the website as tar files or from the [Google Cloud Bucket](https://console.cloud.google.com/storage/browser/waymo_open_dataset_v_1_2_0_individual_files/) as individual tf records. We have already provided the data required to finish this project in the workspace, so you don't need to download it separately.

The data must be download and saved into /home/workspace/data/waymo directory.

### Project overview

This project goal is to train and evaluate an object detection pre-treined model. It consists of three different steps:
- data exploratory analysis: which consists of first insights on the data, and also some conclusion on how to split the training, validation and tests sets.
- data split script: which is a python script which will take the data and split into three groups (training, validation and testing) using the conclusions from previous step
- training and validation part: which shows many different experiments to try to improve the performance of the model in the testing set. The first experiment is used as a reference, and subsequent ones different approaches to try to improve the reference performance.

### Set up
This section should contain a brief description of the steps to follow to run the code for this repository.
For this project, we will be using data from the [Waymo Open dataset](https://waymo.com/open/).

[OPTIONAL] - The files can be downloaded directly from the website as tar files or from the [Google Cloud Bucket](https://console.cloud.google.com/storage/browser/waymo_open_dataset_v_1_2_0_individual_files/) as individual tf records.

### Dataset
#### Dataset analysis
All the data set analysis data is included in the jupyter notebook, with all details and conclusion on how to make the data splits.

Exploratory Data Analysis.ipynb

The data splits is created by runnning the create_splits.py script.

create_splits.py --data-dir "/home/workspace/data/waymo/training_data_set"

The script will create three folders in /home/data folder: train, test and val folders. That will then be used for training and validation.

The create_split script also uses a file of selected records with more diversity of objects, or with objects of all classes. This file is generated by the exploratory python code present in the jupyter notebook.

The splits of the records are done following the proportion: 75% for training, 15% for validation and the other 10% for test. The files selected in by the data analysis are also split following this proportion, and they are excluded from the list with whole files.

Once the create_split is executed, symbolic links are created on the train, eval, and test folders to the original files.

#### Cross validation
A spit of 75% training, 15% validation and 10% testing of files is used. This is selected to have the most proportion of training files, but also to avoid overfitting the data.

### Training
In order to train the model the following script must be run in the workspace folder, pointing to the model_dir used (reference or experiment_01 or 02) also pointing to the right configuration pipeline file.

```
python experiments/model_main_tf2.py --model_dir=experiments/reference/ --pipeline_config_path=experiments/reference/pipeline_new.config
```

Once the training is finished the following command must be run in order to evaluate the model:

```
python experiments/model_main_tf2.py --model_dir=experiments/reference/ --pipeline_config_path=experiments/reference/pipeline_new.config --checkpoint_dir=experiments/reference/
```

#### Reference experiment
This experiment the model from the link below is used:

http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz 

The training, eval, and test datasets are left as is. 

Also, the configuration file for training is the one generated base on ./pipeline.config and placed at ./experiments/reference.

After training and evaluation, the results are as follows:

![alt Reference results](experiments/reference/ref_results.png "tensor flow board with training and eval losses")

The results show that the model converges to a local minima, and reaches loss values of 8.9 in the evaluation set and 8.942 in the training set. 

One of the reasons is that the learning rate reaches zero after 2400 generations, not allowing the optimization get out of local minima. 

Another reason is that the training set need to be increased, this would help to improve the diversity of images which will change the local minimas, and makes the model reach the global minima and not overfit.

#### Improve on the reference
##### Experiment 01

Adding the following augmentations to the configuration file:

- random_rgb_to_gray: this could be useful to not rely on colored images in order to detect object, especially in cases where only a few color dominate the training set.
- random_adjust_brightness: to introduce more images by changing the brightness.
- random_square_crop_by_scale: to crop the existing images and try to zoom in to identify small objects, and also less objects per image, increasing accuracy of the model.

![alt Experiment 1 results](experiments/experiment_01/exp_01_res.png "tensor flow board with training and eval losses")

Given the results above, the local minima stagnation is more pronounced. The model seems to be in better minima and jump to a new one twice.

Although, it does converge to losses values better than the reference. For the training set it reaches 5.94, and to the evaluation set it reaches 5.94. This show that the split are good enough.

This means that a new optimizer with a new learning rate decay strategy would improve the convergency.

#####  Experiment 02

In this experiment the learning rate decay strategy is changed to exponential decay, in order to have very small increments in the end but allowing the model to explore (and not stay in one local minima) in the beginning.

Also the Adam optimizer is chosen in order to experiment and see if other methods can generalize more.


![alt Experiment 2 results](experiments/experiment_02/exp2_res_loss.png "tensor flow board with training and eval losses")

![alt Experiment 2 results Learning rate](experiments/experiment_02/exp2_res_learning_rate.png "tensor flow board with learning rate over time")


In this experiment the training and eval losses are aroun 0.9, less than experiment 1, giving better results than previous experiment.

The generated model is used to create a the testing video.
